# -*- coding: utf-8 -*-
"""breast-cancer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ynE6P2LDLSxJ7e_z900pTMaiLIEECtRT
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv("Copy of 193-15-13521_breast-cancer.csv")

df.head()

plt.figure(figsize=(10, 6))
sns.heatmap(df.isnull(), cbar=False, cmap='viridis')
plt.title('Missing Values Heatmap')
plt.show()

df.isnull().sum()

"""# Label Encoding"""

from sklearn.preprocessing import LabelEncoder

le=LabelEncoder()

one=le.fit_transform(df['age'])

two=le.fit_transform(df['menopause'])

three=le.fit_transform(df['tumor-size'])

four=le.fit_transform(df['inv-nodes'])

five=le.fit_transform(df['node-caps'])

six=le.fit_transform(df['deg-malig'])

seven=le.fit_transform(df['breast'])

eight=le.fit_transform(df['breast-quad'])

nine=le.fit_transform(df['irradiat'])

ten=le.fit_transform(df['Class'])

df['age']=one

df['menopause']=two

df['tumor-size']=three

df['inv-nodes']=four

df['node-caps']=five

df['deg-malig']=six

df['breast']=seven

df['breast-quad']=eight

df['irradiat']=nine

df['class']=ten

df

DF=pd.read_csv("Copy of 193-15-13521_breast-cancer.csv")
DF.head()

def compare_distributions(original, encoded, column_name):
    plt.figure(figsize=(12, 5))
    plt.subplot(1, 2, 1)
    plt.title(f'Original {column_name} Distribution')
    original[column_name].value_counts().plot(kind='bar')

    plt.subplot(1, 2, 2)
    plt.title(f'Encoded {column_name} Distribution')
    encoded[column_name].value_counts().plot(kind='bar')

    plt.tight_layout()
    plt.show()

# Compare the distributions of selected columns (you can add more columns as needed)
compare_distributions(df, DF, 'breast-quad')
compare_distributions(df, DF, 'irradiat')
compare_distributions(df, DF, 'node-caps')

"""# outlier"""

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
sns.boxplot(df['age'])

"""# Co-relation and Normalization"""

df

df1= df.drop("Class",axis=1)
df1

df1.corr()

from sklearn.preprocessing import StandardScaler

sd = StandardScaler()

column_names = df1.columns

column_names

DF_sd_scale = sd.fit_transform(df1)

DF_sd_scale

DF_sd_output = pd.DataFrame(DF_sd_scale,columns=column_names)

DF_sd_output

"""# MinMax

# Taking Numeric dataset
"""

from sklearn.preprocessing import MinMaxScaler

mn = MinMaxScaler()

DF_mn_scaler = mn.fit_transform(df1)

DF_mn_scaler

column_name=df1.columns

DF_mn_output = pd.DataFrame(DF_mn_scaler,columns=column_name)

DF_mn_output.head()

DF['age'].value_counts()

"""# Data Visualization"""

DF['age'].hist()

DF['menopause'].hist()

sns.heatmap(DF.corr(),fmt='.4f')

sns.heatmap(DF.corr(),fmt='.2f',annot=True)

plt.figure(figsize=(20,20))
sns.heatmap(DF.corr(),fmt='.2f', annot=True)

df1.keys()

feature=['age', 'menopause', 'tumor-size', 'inv-nodes', 'node-caps', 'deg-malig',
       'breast', 'breast-quad', 'irradiat']

y=DF_mn_output["class"]

y

x=DF_mn_output[feature]

x.head()

"""# Use Algorithm

# linear Regression
"""

from sklearn.model_selection import train_test_split

X=DF_mn_output.drop('class',axis=1)

X

y=DF_mn_output["class"]
y

x_train,x_test,y_train,y_test=train_test_split(X,y,test_size=.20, random_state=42)

y_train.size

from sklearn.linear_model import LinearRegression

lr=LinearRegression()

lr.fit(x_train,y_train)

pre=lr.predict(x_test)

pre

from sklearn.metrics import r2_score
r2 = r2_score(y_test, pre)

r2

plt.figure(figsize=(8, 6))
sns.scatterplot(x=y_test, y=pre)
plt.xlabel('Actual class')
plt.ylabel('Predicted class')
plt.title('Actual vs. Predicted class (Linear Regression)')
plt.grid(True)

# Add a regression line
sns.regplot(x=y_test, y=pre, scatter=False, color='red')

# Show the plot
plt.show()

# df = pd.DataFrame({'Actual': y_test, 'Predicted': predictions})

# #actual vs predicted plot
# df.plot(kind='bar',figsize=(60,10))
# plt.grid(which='major', linestyle='-', linewidth='0.5', color='green')
# plt.grid(which='minor', linestyle=':', linewidth='0.5', color='black')
# plt.show()

"""# Decision tree"""

from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# Initialize the Decision Tree classifier
clf = DecisionTreeClassifier()

x_train

y_train.size

# Train the classifier on the training data
clf.fit(x_train, y_train)

# Make predictions on the test set
predictions = clf.predict(x_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, predictions)
print(f"Accuracy: {accuracy:.2f}")

"""**KNN**"""

from sklearn.neighbors import KNeighborsClassifier

knn=KNeighborsClassifier()

knn.fit(x_train, y_train)

predictions3 = knn.predict(x_test)

accuracy = accuracy_score(y_test, predictions3)
print(f"Accuracy: {accuracy:.2f}")

from sklearn.ensemble import RandomForestClassifier

"""**Random Forest**"""

RF=RandomForestClassifier()

RF.fit(x_train, y_train)

# Make predictions on the test set
predictions5 = RF.predict(x_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, predictions5)
print(f"Accuracy: {accuracy:.2f}")

"""**Naive Bayes**

"""

from sklearn.naive_bayes import GaussianNB
NB=KNeighborsClassifier()

NB.fit(x_train, y_train)

predictions4 = NB.predict(x_test)

# Calculate accuracy
accuracy = accuracy_score(y_test, predictions4)
print(f"Accuracy: {accuracy:.2f}")